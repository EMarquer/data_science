{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Guidelines:\n",
    "1. Timing:  \n",
    "    you have 20 minutes total: 15 mn for your presentation, 5 mn for discussion with us (Q/A). Make sure not to overrun. \n",
    "2. Slides:  \n",
    "    Please send us your slides before the session.\n",
    "3. Projection:  \n",
    "    We will put your slides on a laptop which will be available for projection. If you use your own laptop, please check beforehand that you can project so as not to waste time.\n",
    "4. Content:  \n",
    "    Your presentation should clearly indicate which parts of the assignments was covered and which was not and it should summarize the results obtained. If you want , you can additionally present a specific point about your work e.g. a code fragment you are particularly proud of or some issue you found with the data/results. This part is free and optional. \n",
    "5. The presentations order is given below.\n",
    "6. Audience:  \n",
    "    the whole class may attend the presentations. \n",
    "\n",
    "\n",
    "10:30 - 10:50\n",
    "MARQUER, Esteban \n",
    "TSAI, Yi Ting\n",
    "\n",
    "Slides tool explanation:  \n",
    "* https://medium.com/@mjspeck/presenting-code-using-jupyter-notebook-slides-a8a3c3b59d67?fbclid=IwAR3B4ReB00mywyf7oh_9mgiuvOnGrij7RUhNfgZ0RQdUEwIsJHyD2RVhX08\n",
    "* https://medium.com/learning-machine-learning/present-your-data-science-projects-with-jupyter-slides-75f20735eb0f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data-Science Project Defense\n",
    "Esteban Marquer & Yi Ting Tsai\n",
    "\n",
    "2019/04/03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline\n",
    "1. **Lab 1**\n",
    "    1. Parts covered and choices\n",
    "    2. Results\n",
    "2. **Lab 2**\n",
    "    1. Parts covered and choices\n",
    "    2. Results\n",
    "3. **Lab 3**\n",
    "    1. Parts covered and choices\n",
    "    2. Results\n",
    "4. **Interesting code fragment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lab 1\n",
    "## Parts covered and choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise 1\n",
    "## Corpus extraction\n",
    "Author selection criterion:\n",
    "- the author must be the **Author** of the book;\n",
    "- the book must not have been chosen for another author (to **avoid book duplicates**);\n",
    "- the book must be written in a certain language;\n",
    "- the book **UTF-8 txt** transcription must be available without error at an expected URL (structured like `http://www.gutenberg.org/ebooks/<book_ID>.txt.utf-8`);\n",
    "- the author must have at least a **certain number of books**. \n",
    "\n",
    "Selected sentences are stored one sentence per line in TXT files, ie [`7524.txt`](https://github.com/EMarquer/data_science/blob/master/lab_1/data/7524.txt), named after Gutenberg identifier. \n",
    "\n",
    "An extra catalogue of books used: [`book_catalogue.csv`](https://github.com/EMarquer/data_science/blob/master/lab_1/data/book_catalogue.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise 2\n",
    "## Querry: abstracts and literary movements\n",
    "Three steps:\n",
    "1. parsing the name of the author given in the Gutenberg project and finding the corresponding name in DBpedia;  \n",
    "> three kind of names (in each case, can be followed by years):\n",
    "> 1. family name, initials (given name)\n",
    "> 2. family name, given name\n",
    "> 3. full name\n",
    "2. getting the URI of the author;\n",
    "3. extracting the abstract (in multiple languages) and the literary movement of the author.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise 3\n",
    "## Aggregation of the data\n",
    "SQL database from the book catalogue [`book_catalogue.csv`](https://github.com/EMarquer/data_science/blob/master/lab_1/data/book_catalogue.csv) and additional information extracted using [`exercise_2.py`](https://github.com/EMarquer/data_science/blob/master/lab_1/exercise_2.py).\n",
    "\n",
    "`ebooks/<book_ID>` Gutenberg project is used as a book URI. \n",
    "\n",
    "![](lab_1/sql_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lab 1\n",
    "## Run and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "AUTHOR_NUMBER = 5  # k\n",
    "SENTENCE_PER_AUTHOR = 200  # n\n",
    "BOOK_THRESHOLD = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>book_url</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dahn, Felix, 1834-1912</td>\n",
       "      <td>/ebooks/32220</td>\n",
       "      <td>A Captive of the Roman Eagles</td>\n",
       "      <td>data\\32220.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dahn, Felix, 1834-1912</td>\n",
       "      <td>/ebooks/32222</td>\n",
       "      <td>Felicitas: A Tale of the German Migrations: A....</td>\n",
       "      <td>data\\32222.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Dahn, Felix, 1834-1912</td>\n",
       "      <td>/ebooks/32443</td>\n",
       "      <td>Saga of Halfred the Sigskald: A Northern Tale ...</td>\n",
       "      <td>data\\32443.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Dahn, Felix, 1834-1912</td>\n",
       "      <td>/ebooks/32461</td>\n",
       "      <td>The Scarlet Banner</td>\n",
       "      <td>data\\32461.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Dahn, Felix, 1834-1912</td>\n",
       "      <td>/ebooks/32271</td>\n",
       "      <td>A Struggle for Rome, v. 1</td>\n",
       "      <td>data\\32271.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Dahn, Felix, 1834-1912</td>\n",
       "      <td>/ebooks/32330</td>\n",
       "      <td>A Struggle for Rome, v. 2</td>\n",
       "      <td>data\\32330.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Dahn, Felix, 1834-1912</td>\n",
       "      <td>/ebooks/32377</td>\n",
       "      <td>A Struggle for Rome, v. 3</td>\n",
       "      <td>data\\32377.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Waddington, Mary King, 1833-1923</td>\n",
       "      <td>/ebooks/14029</td>\n",
       "      <td>Chateau and Country Life in France</td>\n",
       "      <td>data\\14029.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Waddington, Mary King, 1833-1923</td>\n",
       "      <td>/ebooks/37953</td>\n",
       "      <td>Italian Letters of a Diplomat's Wife: January-...</td>\n",
       "      <td>data\\37953.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Waddington, Mary King, 1833-1923</td>\n",
       "      <td>/ebooks/38825</td>\n",
       "      <td>Letters of a Diplomat's Wife, 1883-1900</td>\n",
       "      <td>data\\38825.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Waddington, Mary King, 1833-1923</td>\n",
       "      <td>/ebooks/10003</td>\n",
       "      <td>My First Years as a Frenchwoman, 1876-1879</td>\n",
       "      <td>data\\10003.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                            author       book_url  \\\n",
       "0            0            Dahn, Felix, 1834-1912  /ebooks/32220   \n",
       "1            1            Dahn, Felix, 1834-1912  /ebooks/32222   \n",
       "2            2            Dahn, Felix, 1834-1912  /ebooks/32443   \n",
       "3            3            Dahn, Felix, 1834-1912  /ebooks/32461   \n",
       "4            4            Dahn, Felix, 1834-1912  /ebooks/32271   \n",
       "5            5            Dahn, Felix, 1834-1912  /ebooks/32330   \n",
       "6            6            Dahn, Felix, 1834-1912  /ebooks/32377   \n",
       "7            7  Waddington, Mary King, 1833-1923  /ebooks/14029   \n",
       "8            8  Waddington, Mary King, 1833-1923  /ebooks/37953   \n",
       "9            9  Waddington, Mary King, 1833-1923  /ebooks/38825   \n",
       "10          10  Waddington, Mary King, 1833-1923  /ebooks/10003   \n",
       "\n",
       "                                           book_title       book_file  \n",
       "0                       A Captive of the Roman Eagles  data\\32220.txt  \n",
       "1   Felicitas: A Tale of the German Migrations: A....  data\\32222.txt  \n",
       "2   Saga of Halfred the Sigskald: A Northern Tale ...  data\\32443.txt  \n",
       "3                                  The Scarlet Banner  data\\32461.txt  \n",
       "4                           A Struggle for Rome, v. 1  data\\32271.txt  \n",
       "5                           A Struggle for Rome, v. 2  data\\32330.txt  \n",
       "6                           A Struggle for Rome, v. 3  data\\32377.txt  \n",
       "7                  Chateau and Country Life in France  data\\14029.txt  \n",
       "8   Italian Letters of a Diplomat's Wife: January-...  data\\37953.txt  \n",
       "9             Letters of a Diplomat's Wife, 1883-1900  data\\38825.txt  \n",
       "10         My First Years as a Frenchwoman, 1876-1879  data\\10003.txt  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"lab_1/data/book_catalogue.csv\")\n",
    "df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "df[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "df[11:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "df[22:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "5 first lines of book 0:\n",
    "- Dahn, Felix, 1834-1912\n",
    "- /ebooks/32220\n",
    "- \"A Captive of the Roman Eagles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I was the first on deck, flung, the first brand into the main sail, and swung the Italian lord overboard like a lake salmon out of an ice-hole.\n",
      "--------------------------------------------------\n",
      "But we, Adalo, shall then look down upon the free land of the Alemanni, stretching from the Alps to the Vosges.\n",
      "--------------------------------------------------\n",
      "Skins covered the turf floor which, opposite to the entrance, was raised until it formed a high seat; a curtain of heavy linen hung behind it, dividing from the front of the tent a small space used for a sleeping room.\n",
      "--------------------------------------------------\n",
      "The Illyrian turned toward him with a threatening bearing, saying in a stern, grave tone: \"Who tells you so?\"\n",
      "--------------------------------------------------\n",
      "Davus carried the last cup to the Illyrian and set the silver salver on the table.\n"
     ]
    }
   ],
   "source": [
    "with open(\"lab_1/\" + df[\"book_file\"][0]) as f:\n",
    "    print(('\\n' + '-' * 50 + '\\n').join([line.strip() for line in f][:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lab 2\n",
    "## Parts covered and choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise 1\n",
    "## Pre-processing the previous text files\n",
    "- Remove the punctuation\n",
    "- Get the tokens, the POS and the named entities via Spacy\n",
    "- Run Stanford syntactic parser to get the parse tree\n",
    "\n",
    "Sentences and the additional data are stored in corresponding JSON files, with the name of Gutenberg identifier of the book. \n",
    "`{sentence_ID: [token_POS, ...]}` in `<book>.pos.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise 2\n",
    "## Descriptive statistics\n",
    "Computation of descriptive statistics from processed data of [`exercise_1.py`](https://github.com/EMarquer/data_science/blob/master/lab_2/exercise_1.py):\n",
    "- the vocabulary size (unique token count) per author;\n",
    "- the POS distribution per author;\n",
    "- the mean, max and average number of sentence size (token count), NP and VP per author;\n",
    "- the 10 most frequent named entity per named entity category per author.\n",
    "\n",
    "The generated statistics are not stored but printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise 3\n",
    "## Visualizations\n",
    "- A bar plot for the vocabulary size per author\n",
    "- A box plot for the sentence size per author\n",
    "- A bar plot for the POS distribution per author\n",
    "- A word cloud based on the vocabulary per author, based on the vocabulary of the author\n",
    "\n",
    "The bar plots and box plot are stored in files with representing names. \n",
    "\n",
    "The word clouds are stored in numbered files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lab 2\n",
    "## Run and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise 1 JSON output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "import json \n",
    "with open(\"lab_2/data/32220.pos.json\", 'r') as f:\n",
    "    json_pos = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 0: ['PRON', 'VERB', 'DET', 'ADJ', 'ADP', 'NOUN', 'VERB', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'DET', 'ADJ', 'NOUN', 'ADV', 'ADP', 'DET', 'NOUN', 'NOUN', 'ADP', 'ADP', 'DET', 'NOUN'] \n",
      "\n",
      "sentence 1: ['CCONJ', 'PRON', 'PROPN', 'VERB', 'ADV', 'VERB', 'PART', 'ADP', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'PROPN', 'VERB', 'ADP', 'DET', 'PROPN', 'ADP', 'DET', 'PROPN'] \n",
      "\n",
      "sentence 2: ['NOUN', 'VERB', 'DET', 'NOUN', 'NOUN', 'ADJ', 'ADV', 'ADP', 'DET', 'NOUN', 'VERB', 'VERB', 'ADP', 'PRON', 'VERB', 'DET', 'ADJ', 'NOUN', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'VERB', 'ADP', 'PRON', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'DET', 'ADJ', 'NOUN', 'VERB', 'ADP', 'DET', 'NOUN', 'NOUN'] \n",
      "\n",
      "sentence 3: ['DET', 'PROPN', 'VERB', 'ADP', 'PRON', 'ADP', 'DET', 'ADJ', 'NOUN', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'NOUN', 'VERB', 'PRON', 'ADV'] \n",
      "\n",
      "sentence 4: ['PROPN', 'VERB', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'PROPN', 'CCONJ', 'VERB', 'DET', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN'] \n",
      "\n",
      "sentence 5: ['ADP', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'NUM', 'ADP', 'DET', 'NUM', 'NOUN', 'ADP', 'DET', 'PROPN', 'DET', 'PROPN', 'VERB', 'VERB', 'DET', 'NOUN', 'NOUN', 'ADJ', 'DET', 'NOUN', 'VERB', 'VERB', 'ADP', 'PRON'] \n",
      "\n",
      "sentence 6: ['PROPN', 'VERB', 'PART'] \n",
      "\n",
      "sentence 7: ['PRON'] \n",
      "\n",
      "sentence 8: ['ADJ', 'NOUN', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'VERB', 'PRON', 'DET', 'NOUN'] \n",
      "\n",
      "sentence 9: ['INTJ', 'ADV', 'ADP', 'PROPN', 'PRON', 'VERB', 'VERB', 'PRON'] \n",
      "\n",
      "sentence 10: ['ADJ', 'ADV', 'ADP', 'PRON', 'VERB', 'ADP', 'PRON', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN'] \n",
      "\n",
      "sentence 11: ['ADV', 'PROPN', 'ADP', 'ADJ', 'NOUN'] \n",
      "\n",
      "sentence 12: ['PRON', 'VERB', 'PRON', 'PRON', 'NOUN', 'ADP', 'NOUN', 'PRON', 'VERB', 'ADV'] \n",
      "\n",
      "sentence 13: ['PRON', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN'] \n",
      "\n",
      "sentence 14: ['PRON', 'VERB', 'ADJ'] \n",
      "\n",
      "sentence 15: ['ADV', 'PRON', 'VERB', 'DET', 'ADJ', 'ADJ', 'INTJ', 'NOUN'] \n",
      "\n",
      "sentence 16: ['PROPN', 'VERB', 'PRON', 'VERB', 'DET', 'ADJ'] \n",
      "\n",
      "sentence 17: ['ADP', 'DET', 'NOUN', 'VERB', 'VERB', 'PROPN', 'VERB', 'PROPN', 'DET', 'NOUN', 'NOUN', 'VERB', 'VERB', 'ADJ', 'DET', 'PROPN', 'VERB', 'VERB', 'DET', 'NOUN'] \n",
      "\n",
      "sentence 18: ['ADV', 'DET', 'PROPN', 'ADV', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'PROPN', 'ADV', 'VERB', 'VERB', 'ADP', 'ADJ', 'DET', 'NOUN', 'ADJ', 'ADP', 'PRON', 'VERB', 'VERB', 'VERB', 'ADJ', 'NOUN', 'ADV', 'PART', 'VERB', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PRON'] \n",
      "\n",
      "sentence 19: ['ADP', 'NUM', 'NOUN', 'PRON', 'VERB', 'CCONJ', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'ADP', 'ADV', 'DET', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'NOUN'] \n",
      "\n",
      "sentence 20: ['INTJ'] \n",
      "\n",
      "sentence 21: ['PRON', 'VERB', 'DET', 'NOUN', 'PRON', 'VERB', 'VERB'] \n",
      "\n",
      "sentence 22: ['NOUN', 'VERB'] \n",
      "\n",
      "sentence 23: ['DET', 'ADJ', 'PROPN', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'VERB', 'VERB', 'ADP', 'DET', 'NOUN', 'VERB', 'ADV', 'VERB', 'ADV', 'ADJ', 'VERB', 'VERB', 'ADP', 'DET', 'NOUN'] \n",
      "\n",
      "sentence 24: ['PRON', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADJ', 'NOUN', 'VERB', 'ADP', 'ADJ', 'NOUN', 'VERB', 'DET', 'NOUN', 'VERB', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'CCONJ', 'ADV', 'DET', 'ADJ', 'NOUN', 'VERB', 'ADV', 'ADP', 'DET', 'NOUN', 'NOUN', 'NOUN', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADJ', 'PRON', 'ADV', 'VERB', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'CCONJ', 'ADV', 'VERB', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN'] \n",
      "\n",
      "sentence 25: ['INTJ', 'VERB', 'NOUN'] \n",
      "\n",
      "sentence 26: ['PRON', 'VERB', 'CCONJ', 'VERB', 'CCONJ', 'VERB', 'ADP', 'DET', 'NOUN'] \n",
      "\n",
      "sentence 27: ['PRON', 'VERB', 'PART', 'VERB', 'VERB', 'ADV', 'ADV', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'ADJ', 'NOUN', 'ADJ', 'ADJ', 'NOUN'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in json_pos.items():\n",
    "    print(\"sentence\", key + \":\", value, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise 2 console output\n",
    "![](lab_2-exe_2-screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise 3 images\n",
    "## lab_2/imgs/pos.png\n",
    "![](lab_2/imgs/pos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## lab_2/imgs/voc_size.png\n",
    "![](lab_2/imgs/voc_size.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## lab_2/imgs/box.png\n",
    "![](lab_2/imgs/box.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## lab_2/imgs/00.png\n",
    "![](lab_2/imgs/00.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lab 3\n",
    "## Parts covered and choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise 1\n",
    "## Pre-processing and storage of different features\n",
    "Training and test set : 80% : 20%\n",
    "\n",
    "Obtain following features:\n",
    "- token TF-IDF-normalized frequencies;\n",
    "- named entity TF-IDF-normalized frequencies;\n",
    "- POS-filtered tokens TF-IDF-normalized frequencies;\n",
    "- average VP number per sentence;\n",
    "- average token number per sentence.\n",
    "\n",
    "Saved in SVMLight format to two files : `train.<feature>.svmlight` and `test.<feature>.svmlight`.\n",
    "\n",
    "Mapping of the authors to numbers is done and saved to CSV: `target_to_author.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise 2\n",
    "## Training and optimisation of machine learning models\n",
    "Two classifiers: `MultinomialNB` and `LogisticRegression`\n",
    "Two optimisation scores: `precision_macro` and `recall_macro`  \n",
    "via `GridSearchCV`.\n",
    "\n",
    "In each of the training setup (a feature, a model, and an optimisation score),  \n",
    "the best model found by `GridSearchCV` is tested, and the performance is printed in the console.\n",
    "\n",
    "Visualization: a set of bar plots of each feature (stored into `imgs\\<feature>.png`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise 3\n",
    "## Clustering\n",
    "**We did not do the bonus exercise on clustering**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lab 3\n",
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "INSTANCES_PER_AUTHOR = 50\n",
    "SENTENCES_PER_INSTANCE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## lab_3\\imgs\\ne_tf_idf.png\n",
    "![](lab_3\\imgs\\ne_tf_idf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## lab_3\\imgs\\pos_token_tf_idf.png\n",
    "![](lab_3\\imgs\\pos_token_tf_idf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## lab_3\\imgs\\token_count_mean.png\n",
    "![](lab_3\\imgs\\token_count_mean.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## lab_3\\imgs\\token_tf_idf.png\n",
    "![](lab_3\\imgs\\token_tf_idf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## lab_3\\imgs\\vp_count_mean.png\n",
    "![](lab_3\\imgs\\vp_count_mean.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## lab_3\\imgs\\all.png\n",
    "![](lab_3\\imgs\\all.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interesting code fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Dict of classifier and its corresponding tuning parameters\n",
    "CLF_PARA_DICT = {\n",
    "    MultinomialNB: {'alpha': np.linspace(0.5, 1.5, 6), \n",
    "                    'fit_prior': [True, False]} , \n",
    "    LogisticRegression: {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Erratum\n",
    "In the `README.md` of the three labs, I wrote `Scipy` multiple times instead of `Spacy`.\n",
    "\n",
    "It is corrected on the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank you for your attention !\n",
    "## Questions ?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
